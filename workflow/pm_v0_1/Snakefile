import hashlib
import json
import pathlib
import yaml
import pandas as pd
import datetime
import subprocess
import tempfile

configfile: "config.yaml"

PHAGE_MANIFEST = pathlib.Path(config["manifests"]["phages"])
HOST_MANIFEST = pathlib.Path(config["manifests"]["hosts"])
CACHE_DIR = pathlib.Path(config["directories"]["cache"])
RESULTS_DIR = pathlib.Path(config["directories"]["results"])
TEST_MODE = config["modules"].get("test_mode", False)
ENABLE_SOURMASH = config["modules"].get("enable_sourmash", False) and not TEST_MODE
SOURMASH_K = config.get("params", {}).get("sourmash_k", 21)
SOURMASH_SCALED = config.get("params", {}).get("sourmash_scaled", 2000)
SOURMASH_VERSION = config.get("versions", {}).get("sourmash")
SOURMASH_CACHE = CACHE_DIR / "sourmash"

phages_df = pd.read_csv(PHAGE_MANIFEST, sep="\t") if PHAGE_MANIFEST.exists() else pd.DataFrame(columns=["phage_id","fasta"])
hosts_df = pd.read_csv(HOST_MANIFEST, sep="\t") if HOST_MANIFEST.exists() else pd.DataFrame(columns=["host_id","genome_fna","proteome_faa"])
PHAGE_IDS = phages_df["phage_id"].tolist()
HOST_IDS = hosts_df["host_id"].tolist()


def sha256_file(path: pathlib.Path):
    if not path.exists():
        return None
    h = hashlib.sha256()
    with path.open("rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()


def iso_now():
    return datetime.datetime.now(datetime.timezone.utc).isoformat()

rule all:
    input:
        expand(RESULTS_DIR / "{host_id}" / "ranking.csv", host_id=HOST_IDS),
        expand(RESULTS_DIR / "{host_id}" / "evidence_bundle.json", host_id=HOST_IDS)

rule mock_structures:
    input:
        phage_fasta=lambda wildcards: phages_df.set_index("phage_id").loc[wildcards.phage_id, "fasta"] if not phages_df.empty else "missing",
        host_fasta=lambda wildcards: hosts_df.set_index("host_id").loc[wildcards.host_id, "genome_fna"] if not hosts_df.empty else "missing"
    output:
        CACHE_DIR / "phages" / "{phage_id}" / "mock" / "structures" / "{phage_id}.pdb",
        CACHE_DIR / "hosts" / "{host_id}" / "mock" / "structures" / "{host_id}.pdb"
    run:
        for path in output:
            pathlib.Path(path).parent.mkdir(parents=True, exist_ok=True)
            pathlib.Path(path).write_text(f"MOCK {pathlib.Path(path).stem}\n")

rule sourmash_sketch_phage:
    input:
        fasta=lambda wildcards: phages_df.set_index("phage_id").loc[wildcards.phage_id, "fasta"]
    output:
        sig=SOURMASH_CACHE / "phages" / "{phage_id}.sig"
    conda: "envs/sourmash.yml"
    shell:
        r"""
        mkdir -p $(dirname {output.sig})
        sourmash sketch dna -p k={SOURMASH_K},scaled={SOURMASH_SCALED} {input.fasta} -o {output.sig}
        """

rule sourmash_sketch_host:
    input:
        fasta=lambda wildcards: hosts_df.set_index("host_id").loc[wildcards.host_id, "genome_fna"]
    output:
        sig=SOURMASH_CACHE / "hosts" / "{host_id}.sig"
    conda: "envs/sourmash.yml"
    shell:
        r"""
        mkdir -p $(dirname {output.sig})
        sourmash sketch dna -p k={SOURMASH_K},scaled={SOURMASH_SCALED} {input.fasta} -o {output.sig}
        """

rule sourmash_compare:
    input:
        phage_sig=rules.sourmash_sketch_phage.output.sig,
        host_sig=rules.sourmash_sketch_host.output.sig
    output:
        json=SOURMASH_CACHE / "{host_id}" / "{phage_id}.json"
    conda: "envs/sourmash.yml"
    run:
        out_path = pathlib.Path(output.json)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        # Compute containment (phage vs host) via sourmash compare matrix
        with tempfile.NamedTemporaryFile("w", delete=False, suffix=".csv") as tmp:
            tmp_path = tmp.name
        cmd = [
            "sourmash",
            "compare",
            "--containment",
            "--csv",
            tmp_path,
            input.phage_sig,
            input.host_sig,
        ]
        subprocess.run(cmd, check=True)
        df = pd.read_csv(tmp_path, index_col=0)
        value = float(df.iloc[0, 1]) if not df.empty else 0.0
        payload = {
            "host_id": wildcards.host_id,
            "phage_id": wildcards.phage_id,
            "similarity": value,
            "metric": "containment",
            "tool": "sourmash",
            "tool_version": SOURMASH_VERSION,
            "source": "real",
        }
        out_path.write_text(json.dumps(payload))

rule aggregate_rankings:
    input:
        mocks=expand(CACHE_DIR / "phages" / "{phage_id}" / "mock" / "structures" / "{phage_id}.pdb", phage_id=PHAGE_IDS),
        host_mock=lambda wildcards: CACHE_DIR / "hosts" / wildcards.host_id / "mock" / "structures" / f"{wildcards.host_id}.pdb",
        sourmash=lambda wildcards: [
            SOURMASH_CACHE / wildcards.host_id / f"{pid}.json" for pid in PHAGE_IDS
        ] if ENABLE_SOURMASH else []
    output:
        ranking=RESULTS_DIR / "{host_id}" / "ranking.csv",
        evidence=RESULTS_DIR / "{host_id}" / "evidence_bundle.json"
    run:
        out_dir = pathlib.Path(output.ranking).parent
        out_dir.mkdir(parents=True, exist_ok=True)
        rows = []
        sourmash_scores = {}
        if ENABLE_SOURMASH:
            for pid in PHAGE_IDS:
                feature_path = SOURMASH_CACHE / wildcards.host_id / f"{pid}.json"
                try:
                    feature = json.loads(feature_path.read_text())
                    score = float(feature.get("similarity", 0.0))
                except Exception:
                    score = 0.0
                sourmash_scores[pid] = score

            sorted_phages = sorted(PHAGE_IDS, key=lambda pid: sourmash_scores.get(pid, 0.0), reverse=True)
            for idx, pid in enumerate(sorted_phages):
                rows.append({
                    "host_id": wildcards.host_id,
                    "phage_id": pid,
                    "rank": idx + 1,
                    "confidence_score": sourmash_scores.get(pid, 0.0),
                    "primary_reason": "sourmash_similarity",
                    "safety_flags": "",
                })
        else:
            rows = [
                {
                    "host_id": wildcards.host_id,
                    "phage_id": pid,
                    "rank": idx + 1,
                    "confidence_score": 1.0,
                    "primary_reason": "mock",
                    "safety_flags": "",
                }
                for idx, pid in enumerate(PHAGE_IDS)
            ]

        if not rows:
            rows = [{
                "host_id": wildcards.host_id,
                "phage_id": "none",
                "rank": 1,
                "confidence_score": 0.0,
                "primary_reason": "mock",
                "safety_flags": "",
            }]
        ranking_df = pd.DataFrame(rows)
        ranking_df.to_csv(output.ranking, index=False)

        # Evidence bundle with reproducibility metadata
        evidence = {
            "pipeline_version": "0.1.0",
            "mock": bool(TEST_MODE),
            "run_id": iso_now(),
            "test_mode": bool(TEST_MODE),
            "config_hash": sha256_file(pathlib.Path("config.yaml")),
            "manifest_hashes": {
                "phages": sha256_file(PHAGE_MANIFEST),
                "hosts": sha256_file(HOST_MANIFEST),
            },
            "snapshots": {
                "modules": config.get("modules", {}),
                "params": config.get("params", {}),
                "versions": config.get("versions", {}),
            },
            "features": {
                "sourmash": {
                    "status": "ok" if ENABLE_SOURMASH else "skipped",
                    "source": "real" if ENABLE_SOURMASH else "mock",
                    "metric": "containment",
                    "tool": "sourmash",
                    "tool_version": SOURMASH_VERSION,
                    "reason": None if ENABLE_SOURMASH else "module_disabled_or_test_mode",
                }
            }
        }
        with pathlib.Path(output.evidence).open("w") as f:
            json.dump(evidence, f)
